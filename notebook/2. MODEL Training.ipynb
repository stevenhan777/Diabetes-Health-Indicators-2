{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e99e03",
   "metadata": {},
   "source": [
    "#### Model Training\n",
    "Import Data and Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a7ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db12a06",
   "metadata": {},
   "source": [
    "Import ML models and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5eef8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300c1fa4",
   "metadata": {},
   "source": [
    "Define evaluate_model function to evaluate the following metrics on the true and predicted values:\n",
    "* precision (define each)\n",
    "* recall\n",
    "* f1 score\n",
    "* ROC_AUC\n",
    "* PR_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2ebd379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted, model, X_test):\n",
    "    precision = precision_score(true, predicted , zero_division = 0)\n",
    "    recall = recall_score(true, predicted , zero_division = 0)\n",
    "    f1 = f1_score(true , predicted, zero_division = 0)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    roc_auc = roc_auc_score(true, y_pred_proba)\n",
    "    pr_auc = average_precision_score(true, y_pred_proba)\n",
    "    return precision, recall, f1, roc_auc, pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ec23f",
   "metadata": {},
   "source": [
    "Define function to train and evaluate each model for the scaled data\n",
    "\n",
    "* Logistic Regression (describe each)\n",
    "* Logistic Regression with L1 \n",
    "* Logistic Regression with L2\n",
    "* Support vector classifier\n",
    "* K-Neighbors classifier\n",
    "* Decision tree\n",
    "* Rand forest classifier\n",
    "* XGB classifier\n",
    "* Catboost classifier\n",
    "* Adaboost classifier\n",
    "* Gradient boost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4810c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(),\n",
    "\n",
    "        \"Lasso\": LogisticRegression(penalty='l1', solver='liblinear'),\n",
    "   \n",
    "        \"Ridge\": LogisticRegression(penalty='l2', solver='liblinear'),\n",
    "\n",
    "        #\"Support Vector Machine\": SVC(),\n",
    "\n",
    "        \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "\n",
    "        \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "\n",
    "        \"XGBClassifier\": XGBClassifier(), \n",
    "        \n",
    "        \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "\n",
    "        \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "\n",
    "        \"GradientBoosting Classifier\": GradientBoostingClassifier()\n",
    "    }\n",
    " \n",
    "    # Lists to store results\n",
    "    results_train = []\n",
    "    results_test = []\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    " \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Training predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "        train_precision, train_recall, train_f1, train_roc_auc, train_pr_auc = evaluate_model(\n",
    "            y_train, y_train_pred, model, X_train\n",
    "        )\n",
    "        \n",
    "        # Test predictions\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "        test_precision, test_recall, test_f1, test_roc_auc, test_pr_auc = evaluate_model(\n",
    "            y_test, y_test_pred, model, X_test\n",
    "        )\n",
    "        \n",
    "        # Store training results\n",
    "        results_train.append({\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy_train,\n",
    "            'Precision': train_precision,\n",
    "            'Recall': train_recall,\n",
    "            'F1 Score': train_f1,\n",
    "            'ROC AUC': train_roc_auc,\n",
    "            'PR AUC': train_pr_auc\n",
    "        })\n",
    "        \n",
    "        # Store test results\n",
    "        results_test.append({\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy_test,\n",
    "            'Precision': test_precision,\n",
    "            'Recall': test_recall,\n",
    "            'F1 Score': test_f1,\n",
    "            'ROC AUC': test_roc_auc,\n",
    "            'PR AUC': test_pr_auc\n",
    "        })\n",
    "    \n",
    "    # Create DataFrames\n",
    "    df_train = pd.DataFrame(results_train)\n",
    "    df_test = pd.DataFrame(results_test)\n",
    "    \n",
    "    # Display tables\n",
    "    print(\"=\" * 120)\n",
    "    print(\"TRAINING SET PERFORMANCE\")\n",
    "    print(\"=\" * 120)\n",
    "    print(df_train.to_string(index=False, float_format=lambda x: f'{x:.4f}'))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"=\" * 120)\n",
    "    print(\"TEST SET PERFORMANCE\")\n",
    "    print(\"=\" * 120)\n",
    "    print(df_test.to_string(index=False, float_format=lambda x: f'{x:.4f}'))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa2ce2d",
   "metadata": {},
   "source": [
    "Load in the scaled data to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed6b5645",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.read_csv('data/scaled_unbalanced_X_train.csv')\n",
    "y_train=pd.read_csv('data/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "296e5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=pd.read_csv('data/X_test.csv')\n",
    "y_test=pd.read_csv('data/y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d21586",
   "metadata": {},
   "source": [
    "Run the models with the scaled and unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1853f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\n",
      "LogisticRegression(penalty='l1', solver='liblinear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "LogisticRegression(solver='liblinear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Neighbors Classifier\n",
      "KNeighborsClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "DecisionTreeClassifier()\n",
      "Random Forest Classifier\n",
      "RandomForestClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              feature_weights=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
      "              n_jobs=None, num_parallel_tree=None, ...)\n",
      "CatBoosting Classifier\n",
      "<catboost.core.CatBoostClassifier object at 0x000002328162A5D0>\n",
      "AdaBoost Classifier\n",
      "AdaBoostClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting Classifier\n",
      "GradientBoostingClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "TRAINING SET PERFORMANCE\n",
      "========================================================================================================================\n",
      "                      Model  Accuracy  Precision  Recall  F1 Score  ROC AUC  PR AUC\n",
      "        Logistic Regression    0.8475     0.5512  0.1815    0.2730   0.8142  0.4290\n",
      "                      Lasso    0.8475     0.5514  0.1816    0.2732   0.8143  0.4289\n",
      "                      Ridge    0.8475     0.5517  0.1815    0.2731   0.8142  0.4290\n",
      "     K-Neighbors Classifier    0.8733     0.6799  0.3736    0.4822   0.8957  0.5518\n",
      "              Decision Tree    0.9871     0.9969  0.9209    0.9574   0.9992  0.9947\n",
      "   Random Forest Classifier    0.9870     0.9885  0.9287    0.9576   0.9972  0.9910\n",
      "              XGBClassifier    0.8598     0.6556  0.2358    0.3468   0.8432  0.5225\n",
      "     CatBoosting Classifier    0.8627     0.6829  0.2434    0.3589   0.8443  0.5411\n",
      "        AdaBoost Classifier    0.8493     0.5580  0.2179    0.3134   0.8184  0.4477\n",
      "GradientBoosting Classifier    0.8512     0.5819  0.2041    0.3022   0.8233  0.4602\n",
      "\n",
      "\n",
      "========================================================================================================================\n",
      "TEST SET PERFORMANCE\n",
      "========================================================================================================================\n",
      "                      Model  Accuracy  Precision  Recall  F1 Score  ROC AUC  PR AUC\n",
      "        Logistic Regression    0.1565     0.1565  1.0000    0.2707   0.5000  0.1565\n",
      "                      Lasso    0.1565     0.1565  1.0000    0.2707   0.5000  0.1565\n",
      "                      Ridge    0.1565     0.1565  1.0000    0.2707   0.5000  0.1565\n",
      "     K-Neighbors Classifier    0.7028     0.2625  0.4969    0.3435   0.6398  0.2224\n",
      "              Decision Tree    0.7998     0.3408  0.2986    0.3183   0.5957  0.2115\n",
      "   Random Forest Classifier    0.7630     0.3365  0.5292    0.4114   0.7231  0.3331\n",
      "              XGBClassifier    0.3555     0.1705  0.8066    0.2815   0.5983  0.2019\n",
      "     CatBoosting Classifier    0.6528     0.2517  0.6176    0.3577   0.6674  0.2634\n",
      "        AdaBoost Classifier    0.8318     0.4231  0.2059    0.2770   0.7614  0.3440\n",
      "GradientBoosting Classifier    0.2973     0.1646  0.8559    0.2760   0.4540  0.1610\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c4699",
   "metadata": {},
   "source": [
    "Observations:\n",
    "Looking at ROC_AUC, Adaboost performs best, with also best PR AUC\n",
    "Random forest has best f1 score\n",
    "\n",
    "Intepreting this with unbalanced dataset we would want to penalize misclassifying the minority class (1 diabetes) more heavily - which means we want to maximize precision (minimizing false positives).\n",
    "\n",
    "ONce again, Adaboost has best precision and probably would be model of choice for unbalanced and scaled data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b63b8c",
   "metadata": {},
   "source": [
    "Load in the scaled and Balanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb66988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.read_csv('data/scaled_balanced_X_train.csv')\n",
    "y_train=pd.read_csv('data/scaled_balanced_y_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec0673c",
   "metadata": {},
   "source": [
    "Run the classification models on the scaled and Balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "914cc3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "TRAINING SET PERFORMANCE\n",
      "========================================================================================================================\n",
      "                      Model  Accuracy  Precision  Recall  F1 Score  ROC AUC  PR AUC\n",
      "        Logistic Regression    0.7428     0.7337  0.7624    0.7478   0.8172  0.7819\n",
      "                      Lasso    0.7429     0.7338  0.7623    0.7478   0.8172  0.7819\n",
      "                      Ridge    0.7428     0.7337  0.7622    0.7477   0.8172  0.7819\n",
      "     K-Neighbors Classifier    0.8562     0.8098  0.9311    0.8662   0.9475  0.9331\n",
      "              Decision Tree    0.9898     0.9981  0.9814    0.9897   0.9998  0.9997\n",
      "   Random Forest Classifier    0.9897     0.9938  0.9856    0.9897   0.9991  0.9992\n",
      "              XGBClassifier    0.8662     0.9089  0.8141    0.8589   0.9447  0.9547\n",
      "     CatBoosting Classifier    0.8755     0.9212  0.8213    0.8684   0.9492  0.9588\n",
      "        AdaBoost Classifier    0.7892     0.7756  0.8139    0.7943   0.8755  0.8761\n",
      "GradientBoosting Classifier    0.8328     0.8305  0.8364    0.8334   0.9205  0.9300\n",
      "\n",
      "\n",
      "========================================================================================================================\n",
      "TEST SET PERFORMANCE\n",
      "========================================================================================================================\n",
      "                      Model  Accuracy  Precision  Recall  F1 Score  ROC AUC  PR AUC\n",
      "        Logistic Regression    0.1565     0.1565  1.0000    0.2707   0.5000  0.1565\n",
      "                      Lasso    0.1565     0.1565  1.0000    0.2707   0.5000  0.1565\n",
      "                      Ridge    0.1565     0.1565  1.0000    0.2707   0.5000  0.1565\n",
      "     K-Neighbors Classifier    0.6361     0.2519  0.6728    0.3666   0.6668  0.2331\n",
      "              Decision Tree    0.5149     0.1360  0.3921    0.2019   0.4649  0.1485\n",
      "   Random Forest Classifier    0.6308     0.2570  0.7185    0.3786   0.7093  0.2692\n",
      "              XGBClassifier    0.6160     0.2090  0.5220    0.2985   0.6340  0.2741\n",
      "     CatBoosting Classifier    0.6700     0.2050  0.3850    0.2675   0.5822  0.2496\n",
      "        AdaBoost Classifier    0.1789     0.1598  0.9976    0.2755   0.7242  0.2802\n",
      "GradientBoosting Classifier    0.1789     0.1598  0.9976    0.2755   0.7139  0.2709\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4fb71f",
   "metadata": {},
   "source": [
    "Observations of results:\n",
    "\n",
    "Adaboost once again with the balanced dataset has best ROC_AUC and best PR AUC\n",
    "\n",
    "Ada boost and gradient boost are very good on recall but low on precision\n",
    "\n",
    "Once again random forest has best f1 score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cdf165",
   "metadata": {},
   "source": [
    "Define function for models that do not require scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d0911c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_scale_classification(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    models = {\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "\n",
    "        \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "\n",
    "        \"XGBClassifier\": XGBClassifier(), \n",
    "        \n",
    "        \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "\n",
    "        \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "\n",
    "        \"GradientBoosting Classifier\": GradientBoostingClassifier()\n",
    "    }\n",
    " \n",
    "    # Lists to store results\n",
    "    results_train = []\n",
    "    results_test = []\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Training predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "        train_precision, train_recall, train_f1, train_roc_auc, train_pr_auc = evaluate_model(\n",
    "            y_train, y_train_pred, model, X_train\n",
    "        )\n",
    "        \n",
    "        # Test predictions\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "        test_precision, test_recall, test_f1, test_roc_auc, test_pr_auc = evaluate_model(\n",
    "            y_test, y_test_pred, model, X_test\n",
    "        )\n",
    "        \n",
    "        # Store training results\n",
    "        results_train.append({\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy_train,\n",
    "            'Precision': train_precision,\n",
    "            'Recall': train_recall,\n",
    "            'F1 Score': train_f1,\n",
    "            'ROC AUC': train_roc_auc,\n",
    "            'PR AUC': train_pr_auc\n",
    "        })\n",
    "        \n",
    "        # Store test results\n",
    "        results_test.append({\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy_test,\n",
    "            'Precision': test_precision,\n",
    "            'Recall': test_recall,\n",
    "            'F1 Score': test_f1,\n",
    "            'ROC AUC': test_roc_auc,\n",
    "            'PR AUC': test_pr_auc\n",
    "        })\n",
    "    \n",
    "    # Create DataFrames\n",
    "    df_train = pd.DataFrame(results_train)\n",
    "    df_test = pd.DataFrame(results_test)\n",
    "    \n",
    "    # Display tables\n",
    "    print(\"=\" * 120)\n",
    "    print(\"TRAINING SET PERFORMANCE\")\n",
    "    print(\"=\" * 120)\n",
    "    print(df_train.to_string(index=False, float_format=lambda x: f'{x:.4f}'))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"=\" * 120)\n",
    "    print(\"TEST SET PERFORMANCE\")\n",
    "    print(\"=\" * 120)\n",
    "    print(df_test.to_string(index=False, float_format=lambda x: f'{x:.4f}'))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9b1229",
   "metadata": {},
   "source": [
    "Load in the unscaled and unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3531de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.read_csv('data/unscaled_unbalanced_X_train.csv')\n",
    "y_train=pd.read_csv('data/y_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042d234",
   "metadata": {},
   "source": [
    "Run the classification on the unscaled and unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af73e466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "TRAINING SET PERFORMANCE\n",
      "========================================================================================================================\n",
      "                      Model  Accuracy  Precision  Recall  F1 Score  ROC AUC  PR AUC\n",
      "              Decision Tree    0.9871     0.9969  0.9209    0.9574   0.9992  0.9947\n",
      "   Random Forest Classifier    0.9870     0.9890  0.9282    0.9576   0.9973  0.9910\n",
      "              XGBClassifier    0.8598     0.6556  0.2358    0.3468   0.8432  0.5225\n",
      "     CatBoosting Classifier    0.8627     0.6829  0.2434    0.3589   0.8443  0.5411\n",
      "        AdaBoost Classifier    0.8493     0.5580  0.2179    0.3134   0.8184  0.4477\n",
      "GradientBoosting Classifier    0.8512     0.5819  0.2041    0.3022   0.8233  0.4602\n",
      "\n",
      "\n",
      "========================================================================================================================\n",
      "TEST SET PERFORMANCE\n",
      "========================================================================================================================\n",
      "                      Model  Accuracy  Precision  Recall  F1 Score  ROC AUC  PR AUC\n",
      "              Decision Tree    0.7851     0.3220  0.3374    0.3295   0.5979  0.2157\n",
      "   Random Forest Classifier    0.8396     0.4739  0.2278    0.3077   0.7856  0.3794\n",
      "              XGBClassifier    0.8506     0.5616  0.2061    0.3016   0.8221  0.4474\n",
      "     CatBoosting Classifier    0.8510     0.5662  0.2040    0.2999   0.8238  0.4503\n",
      "        AdaBoost Classifier    0.8515     0.5628  0.2286    0.3251   0.8231  0.4496\n",
      "GradientBoosting Classifier    0.8522     0.5758  0.2104    0.3082   0.8262  0.4564\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_scale_classification(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c49812",
   "metadata": {},
   "source": [
    "Observations on the unscaled vs scaled unbalanced data:\n",
    "\n",
    "All the boosting models: XGB, CatBoost, AdaBoost and GradientBoosting have similar ROC AUC scores and PR AUC. Gradient boost has the best scores here.\n",
    "\n",
    "These scores are higher with unscaled data.\n",
    "With unbalanced data to max precision, gradient boosting also scores highest. \n",
    "\n",
    "Decision tree has best f1 score again. \n",
    "\n",
    "I would choose gradient boost for unscaled unbalanced data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38430c29",
   "metadata": {},
   "source": [
    "Load in the unscaled and Balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5aae376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.read_csv('data/unscaled_balanced_X_train.csv')\n",
    "y_train=pd.read_csv('data/unscaled_balanced_y_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8146c31",
   "metadata": {},
   "source": [
    "Run the classification models on unscaled and balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db94a0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\steve\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "TRAINING SET PERFORMANCE\n",
      "========================================================================================================================\n",
      "                      Model  Accuracy  Precision  Recall  F1 Score  ROC AUC  PR AUC\n",
      "              Decision Tree    0.9898     0.9981  0.9814    0.9897   0.9998  0.9997\n",
      "   Random Forest Classifier    0.9897     0.9942  0.9852    0.9897   0.9992  0.9993\n",
      "              XGBClassifier    0.8663     0.9062  0.8173    0.8595   0.9449  0.9548\n",
      "     CatBoosting Classifier    0.8758     0.9196  0.8235    0.8689   0.9498  0.9592\n",
      "        AdaBoost Classifier    0.8165     0.8107  0.8259    0.8182   0.9063  0.9162\n",
      "GradientBoosting Classifier    0.8455     0.8592  0.8265    0.8425   0.9298  0.9404\n",
      "\n",
      "\n",
      "========================================================================================================================\n",
      "TEST SET PERFORMANCE\n",
      "========================================================================================================================\n",
      "                      Model  Accuracy  Precision  Recall  F1 Score  ROC AUC  PR AUC\n",
      "              Decision Tree    0.7508     0.2958  0.4288    0.3501   0.6167  0.2197\n",
      "   Random Forest Classifier    0.8130     0.4074  0.4279    0.4174   0.7882  0.3756\n",
      "              XGBClassifier    0.8344     0.4696  0.4496    0.4593   0.8226  0.4509\n",
      "     CatBoosting Classifier    0.8372     0.4778  0.4307    0.4530   0.8230  0.4509\n",
      "        AdaBoost Classifier    0.7802     0.3807  0.6451    0.4788   0.8175  0.4395\n",
      "GradientBoosting Classifier    0.8136     0.4261  0.5501    0.4802   0.8229  0.4490\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_scale_classification(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ce711",
   "metadata": {},
   "source": [
    "Observations of results\n",
    "\n",
    "XGB, catboost and gradient boost are top in ROC _AUC\n",
    "XGB and catboost have best PR_AUC\n",
    "\n",
    "The precision and recall scores across models are more balanced for the balanced data than unbalanced, which is to be expected.\n",
    "\n",
    "The f1 score is also better.\n",
    "\n",
    "Overall, I would choose gradient boosting model since has overall better scores acros multiple metircs. \n",
    "\n",
    "Overall, the precision and recall is more blaanced and f1 score is better across models for balanced dataset, so i would choose balaced.\n",
    "\n",
    "Overall, ROC_AUC and PR_AUC is better for unscaled data, with the mdoels requiring scaling (logistic regression, k neighbors) not performing substantially better (acutally still worse) then the models that do not require feature scaling.\n",
    "\n",
    "So I will choose to leave data unscaled for best model. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
