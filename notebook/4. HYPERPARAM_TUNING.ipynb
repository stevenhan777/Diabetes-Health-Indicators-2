{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9574c5c2",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning\n",
    "\n",
    "Here I will do hyperparameter tuning on the models on the dataset that is balanced and unscaled as that determined the best dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8f08e0",
   "metadata": {},
   "source": [
    "Import required packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7028426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a611e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec47bfe9",
   "metadata": {},
   "source": [
    "Define the evaluate_model function as done in Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26857c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted, model, X_test):\n",
    "    precision = precision_score(true, predicted , zero_division = 0)\n",
    "    recall = recall_score(true, predicted , zero_division = 0)\n",
    "    f1 = f1_score(true , predicted, zero_division = 0)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    roc_auc = roc_auc_score(true, y_pred_proba)\n",
    "    pr_auc = average_precision_score(true, y_pred_proba)\n",
    "    return precision, recall, f1, roc_auc, pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4e8eea",
   "metadata": {},
   "source": [
    "Define the no_scale_classification function as defined in Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad6403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_scale_classification_hyperparam_tuning(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Models with hyperparameter tuning\n",
    "    tuned_models = {\n",
    "        \"Decision Tree\": {\n",
    "            \"model\": DecisionTreeClassifier(random_state=42),\n",
    "            \"params\": {\n",
    "                'max_depth': [3, 5, 7, 10, 15, 20, None],\n",
    "                'min_samples_split': [2, 5, 10, 20],\n",
    "                'min_samples_leaf': [1, 2, 4, 8],\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_features': ['sqrt', 'log2', None],\n",
    "                'class_weight': ['balanced', None]\n",
    "            }\n",
    "        },\n",
    "        \"Random Forest\": {\n",
    "            \"model\": RandomForestClassifier(random_state=42),\n",
    "            \"params\": {\n",
    "                'n_estimators': [50, 100, 200, 300],\n",
    "                'max_depth': [5, 10, 15, 20, None],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4],\n",
    "                'max_features': ['sqrt', 'log2'],\n",
    "                'class_weight': ['balanced', 'balanced_subsample', None],\n",
    "                'bootstrap': [True, False]\n",
    "            }\n",
    "        },\n",
    "        \"XGBoost\": {\n",
    "            \"model\": XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "            \"params\": {\n",
    "                'n_estimators': [50, 100, 200, 300],\n",
    "                'max_depth': [3, 5, 7, 9],\n",
    "                'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "                'subsample': [0.6, 0.8, 1.0],\n",
    "                'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "                'gamma': [0, 0.1, 0.5, 1],\n",
    "                'min_child_weight': [1, 3, 5],\n",
    "                'scale_pos_weight': [1, 2, 3]\n",
    "            }\n",
    "        },\n",
    "        \"CatBoost\": {\n",
    "            \"model\": CatBoostClassifier(random_state=42, verbose=False),\n",
    "            \"params\": {\n",
    "                'iterations': [50, 100, 200, 300],\n",
    "                'depth': [4, 6, 8, 10],\n",
    "                'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "                'l2_leaf_reg': [1, 3, 5, 7],\n",
    "                'border_count': [32, 64, 128],\n",
    "                'class_weights': [[1, 1], [1, 2], [1, 3]]\n",
    "            }\n",
    "        },\n",
    "        \"AdaBoost\": {\n",
    "            \"model\": AdaBoostClassifier(random_state=42),\n",
    "            \"params\": {\n",
    "                'n_estimators': [50, 100, 200, 300],\n",
    "                'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
    "                'algorithm': ['SAMME', 'SAMME.R']\n",
    "            }\n",
    "        },\n",
    "        \"GradientBoosting\": {\n",
    "            \"model\": GradientBoostingClassifier(random_state=42),\n",
    "            \"params\": {\n",
    "                'n_estimators': [50, 100, 200, 300],\n",
    "                'max_depth': [3, 5, 7, 9],\n",
    "                'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "                'subsample': [0.6, 0.8, 1.0],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4],\n",
    "                'max_features': ['sqrt', 'log2', None]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Train models with hyperparameter tuning\n",
    "    print(\"\\nTraining models with hyperparameter tuning...\")\n",
    "    for model_name, model_info in tuned_models.items():\n",
    "        print(f\"  - {model_name} (this may take a while...)\")\n",
    "        \n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=model_info[\"model\"],\n",
    "            param_distributions=model_info[\"params\"],\n",
    "            n_iter=50,\n",
    "            cv=5,\n",
    "            scoring='roc_auc',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        random_search.fit(X_train, y_train)\n",
    "        best_model = random_search.best_estimator_\n",
    "        \n",
    "        y_train_pred = best_model.predict(X_train)\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        \n",
    "        accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "        accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "        \n",
    "        train_precision, train_recall, train_f1, train_roc_auc, train_pr_auc = evaluate_model(\n",
    "            y_train, y_train_pred, best_model, X_train\n",
    "        )\n",
    "        test_precision, test_recall, test_f1, test_roc_auc, test_pr_auc = evaluate_model(\n",
    "            y_test, y_test_pred, best_model, X_test\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Train Accuracy': accuracy_train,\n",
    "            'Test Accuracy': accuracy_test,\n",
    "            'Test Precision': test_precision,\n",
    "            'Test Recall': test_recall,\n",
    "            'Test F1': test_f1,\n",
    "            'Test ROC AUC': test_roc_auc,\n",
    "            'Test PR AUC': test_pr_auc,\n",
    "            'Tuned': 'Yes',\n",
    "            'Best Params': str(random_search.best_params_)\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    # Display main results table\n",
    "    print(\"\\n\" + \"=\" * 150)\n",
    "    print(\"MODEL COMPARISON - ALL METRICS\")\n",
    "    print(\"=\" * 150)\n",
    "    display_df = df_results.drop('Best Params', axis=1)\n",
    "    print(display_df.to_string(index=False, float_format=lambda x: f'{x:.4f}'))\n",
    "    \n",
    "    # Display best parameters for tuned models\n",
    "    print(\"\\n\" + \"=\" * 150)\n",
    "    print(\"BEST HYPERPARAMETERS FOR TUNED MODELS\")\n",
    "    print(\"=\" * 150)\n",
    "    tuned_df = df_results[df_results['Tuned'] == 'Yes'][['Model', 'Best Params']]\n",
    "    for idx, row in tuned_df.iterrows():\n",
    "        print(f\"\\n{row['Model']}:\")\n",
    "        params = eval(row['Best Params'])\n",
    "        for param, value in params.items():\n",
    "            print(f\"  - {param}: {value}\")\n",
    "    \n",
    "    # Display sorted by Test ROC AUC\n",
    "    print(\"\\n\" + \"=\" * 150)\n",
    "    print(\"TOP 5 MODELS BY TEST ROC AUC\")\n",
    "    print(\"=\" * 150)\n",
    "    top_models = df_results.nlargest(5, 'Test ROC AUC')[['Model', 'Test Accuracy', 'Test ROC AUC', 'Test F1', 'Tuned']]\n",
    "    print(top_models.to_string(index=False, float_format=lambda x: f'{x:.4f}'))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b9a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_scale_classification(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    models = {\n",
    "        \"Decision Tree\": DecisionTreeClassifier(),\n",
    "\n",
    "        \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "\n",
    "        \"XGBClassifier\": XGBClassifier(), \n",
    "        \n",
    "        \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "\n",
    "        \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "\n",
    "        \"GradientBoosting Classifier\": GradientBoostingClassifier()\n",
    "    }\n",
    " \n",
    "    # Lists to store results\n",
    "    results_train = []\n",
    "    results_test = []\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Training predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "        train_precision, train_recall, train_f1, train_roc_auc, train_pr_auc = evaluate_model(\n",
    "            y_train, y_train_pred, model, X_train\n",
    "        )\n",
    "        \n",
    "        # Test predictions\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "        test_precision, test_recall, test_f1, test_roc_auc, test_pr_auc = evaluate_model(\n",
    "            y_test, y_test_pred, model, X_test\n",
    "        )\n",
    "        \n",
    "        # Store training results\n",
    "        results_train.append({\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy_train,\n",
    "            'Precision': train_precision,\n",
    "            'Recall': train_recall,\n",
    "            'F1 Score': train_f1,\n",
    "            'ROC AUC': train_roc_auc,\n",
    "            'PR AUC': train_pr_auc\n",
    "        })\n",
    "        \n",
    "        # Store test results\n",
    "        results_test.append({\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy_test,\n",
    "            'Precision': test_precision,\n",
    "            'Recall': test_recall,\n",
    "            'F1 Score': test_f1,\n",
    "            'ROC AUC': test_roc_auc,\n",
    "            'PR AUC': test_pr_auc\n",
    "        })\n",
    "    \n",
    "    # Create DataFrames\n",
    "    df_train = pd.DataFrame(results_train)\n",
    "    df_test = pd.DataFrame(results_test)\n",
    "    \n",
    "    # Display tables\n",
    "    print(\"=\" * 120)\n",
    "    print(\"TRAINING SET PERFORMANCE\")\n",
    "    print(\"=\" * 120)\n",
    "    print(df_train.to_string(index=False, float_format=lambda x: f'{x:.4f}'))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"=\" * 120)\n",
    "    print(\"TEST SET PERFORMANCE\")\n",
    "    print(\"=\" * 120)\n",
    "    print(df_test.to_string(index=False, float_format=lambda x: f'{x:.4f}'))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f91a2d",
   "metadata": {},
   "source": [
    "Load in the unscaled and balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b83e258",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.read_csv('data/unscaled_balanced_X_train.csv')\n",
    "y_train=pd.read_csv('data/unscaled_balanced_y_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0880e80f",
   "metadata": {},
   "source": [
    "Load in the test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c04199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=pd.read_csv('data/X_test.csv')\n",
    "y_test=pd.read_csv('data/y_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
